{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61ba86c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520ff620",
   "metadata": {},
   "source": [
    "## Tree Implementation\n",
    "    \n",
    "    - Class Node\n",
    "        - contains some default values such as information gain , entropy threshold and feature_index on which it    divided the dataset\n",
    "    - class DecisionTreeClassfier\n",
    "        - it contains the functions for building the decision tree, calculating information gain , entropy with other helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4634067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Node for tree\n",
    "class Node:\n",
    "    def __init__(self,feature_index=None,threshold=None,left=None,right=None,info_gain=None,entropy=None,value=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "        self.entropy = entropy\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "045b69a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier class\n",
    "class myDecisionTreeClassifier():\n",
    "    def __init__(self, min_samples_split=2, max_depth=2,feature_list=[],target_list=[]):\n",
    "        ''' constructor '''\n",
    "        # initialize the root of the tree \n",
    "        self.root = None\n",
    "        # stopping conditions\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        # feature list and target lists\n",
    "        self.feature_list = feature_list\n",
    "        self.target_list = target_list\n",
    "        \n",
    "    def build_tree(self, dataset, curr_depth=0):\n",
    "        ''' recursive function to build the tree ''' \n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
    "        num_samples, num_features = np.shape(X)\n",
    "        \n",
    "        # printing the current node metadata of tree\n",
    "        print('\\nLevel ',curr_depth)\n",
    "        val,count = np.unique(Y,return_counts=True)\n",
    "#         print(val,count)\n",
    "#         print('Y:',Y)\n",
    "#         print(dataset)\n",
    "        val,count = [int(i) for i in val],[int(j) for j in count]\n",
    "        for idx in range(len(val)):\n",
    "#             print(int(uv),type(uv))\n",
    "            print('Count of '+str(self.target_list[val[idx]])+' = '+str(count[idx]))\n",
    "        \n",
    "        # split until stopping conditions are met\n",
    "        if num_samples>=self.min_samples_split and curr_depth<=self.max_depth:\n",
    "            # find the best split\n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            # check if information gain is positive\n",
    "            if best_split[\"info_gain\"]>0:\n",
    "                # print the node parameters\n",
    "                gain_ratio = best_split[\"info_gain\"]/best_split[\"entropy_curr_node\"]\n",
    "                print('Current Entropy is = '+str(best_split[\"entropy_curr_node\"]))\n",
    "                print('Splitting on feature '+str(self.feature_list[best_split[\"feature_index\"]])+' with gain ratio = '+str(gain_ratio))\n",
    "                \n",
    "                # recur left\n",
    "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n",
    "                # recur right\n",
    "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n",
    "                # return decision node\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"],left_subtree, right_subtree, best_split[\"info_gain\"],best_split[\"entropy_curr_node\"])\n",
    "        \n",
    "        # compute leaf node\n",
    "        print('Current entropy is = 0.0')\n",
    "        print('Reached leaf node')\n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "        # return leaf node\n",
    "        return Node(value=leaf_value)\n",
    "    \n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "        ''' function to find the best split '''\n",
    "        \n",
    "        # dictionary to store the best split\n",
    "        best_split = {}\n",
    "        max_info_gain = -float(\"inf\")\n",
    "        \n",
    "        # loop over all the features\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = dataset[:, feature_index]\n",
    "            possible_thresholds = np.unique(feature_values)\n",
    "            # loop over all the feature values present in the data\n",
    "            for threshold in possible_thresholds:\n",
    "                # get current split\n",
    "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "                # check if childs are not null\n",
    "                if len(dataset_left)>0 and len(dataset_right)>0:\n",
    "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "                    # compute information gain\n",
    "                    curr_info_gain, curr_entropy = self.information_gain(y, left_y, right_y, \"gini\")\n",
    "                    # update the best split if needed\n",
    "                    if curr_info_gain>max_info_gain:\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"info_gain\"] = curr_info_gain\n",
    "                        best_split[\"entropy_curr_node\"] = curr_entropy\n",
    "                        max_info_gain = curr_info_gain\n",
    "                        \n",
    "        return best_split\n",
    "    \n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        ''' function to split the data '''\n",
    "        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
    "        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n",
    "        return dataset_left, dataset_right\n",
    "    \n",
    "    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n",
    "        ''' function to compute information gain '''\n",
    "        \n",
    "        weight_l = len(l_child) / len(parent)\n",
    "        weight_r = len(r_child) / len(parent)\n",
    "        entropy_parent = self.entropy(parent)\n",
    "        if mode==\"gini\":\n",
    "            gain = self.gini_index(parent) - (weight_l*self.gini_index(l_child) + weight_r*self.gini_index(r_child))\n",
    "        else:\n",
    "            gain = entropy_parent - (weight_l*self.entropy(l_child) + weight_r*self.entropy(r_child))\n",
    "        return gain,entropy_parent\n",
    "    \n",
    "    def entropy(self, y):\n",
    "        ''' function to compute entropy '''\n",
    "        class_labels = np.unique(y)\n",
    "        entropy = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            entropy += -p_cls * np.log2(p_cls)\n",
    "        return entropy\n",
    "    \n",
    "    def gini_index(self, y):\n",
    "        ''' function to compute gini index '''\n",
    "#         print('y =>',y)\n",
    "        class_labels = np.unique(y)\n",
    "#         print('here')\n",
    "        gini = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            gini += p_cls**2\n",
    "        return 1 - gini\n",
    "    \n",
    "    def get_unique_counts(self,y):\n",
    "        l = np.unique(y)\n",
    "        print()\n",
    "    def calculate_leaf_value(self, Y):\n",
    "        ''' function to compute leaf node '''\n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        ''' function to train the tree '''\n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        ''' function to predict new dataset '''\n",
    "        preditions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return preditions\n",
    "    \n",
    "    def make_prediction(self, x, tree):\n",
    "        ''' function to predict a single data point '''\n",
    "        if tree.value!=None: return tree.value\n",
    "        feature_val = x[tree.feature_index]\n",
    "        if feature_val<=tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad8e071",
   "metadata": {},
   "source": [
    "# IRIS Dataset\n",
    "\n",
    "### dataset preprocessing\n",
    "     - loading the dataset and doing some basic preprocessing before giving it as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcb2a2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 6.0 KB\n",
      "None\n",
      "0    50\n",
      "1    50\n",
      "2    50\n",
      "Name: species, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = pd.read_csv('iris.csv')\n",
    "iris_data['species'].value_counts()\n",
    "dd={\n",
    "    'Iris-setosa':0,\n",
    "    'Iris-versicolor':1,\n",
    "    'Iris-virginica':2\n",
    "}\n",
    "iris_data['species'].replace(dd,inplace=True)\n",
    "f_list = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "t_list = list(dd.keys())\n",
    "print(iris_data.info())\n",
    "print(iris_data['species'].value_counts())\n",
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af60a0d",
   "metadata": {},
   "source": [
    "### testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e67b105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris_data.iloc[:, :-1].values\n",
    "Y = iris_data.iloc[:, -1].values.reshape(-1,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e50688b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Level  0\n",
      "Count of Iris-setosa = 41\n",
      "Count of Iris-versicolor = 39\n",
      "Count of Iris-virginica = 40\n",
      "Current Entropy is = 1.5846619079379884\n",
      "Splitting on feature petal_length with gain ratio = 0.21292482140004135\n",
      "\n",
      "Level  1\n",
      "Count of Iris-setosa = 41\n",
      "Current entropy is = 0.0\n",
      "Reached leaf node\n",
      "\n",
      "Level  1\n",
      "Count of Iris-versicolor = 39\n",
      "Count of Iris-virginica = 40\n",
      "Current Entropy is = 0.9998844148717589\n",
      "Splitting on feature petal_width with gain ratio = 0.4271560110626066\n",
      "\n",
      "Level  2\n",
      "Count of Iris-versicolor = 37\n",
      "Count of Iris-virginica = 1\n",
      "Current Entropy is = 0.17556502585750278\n",
      "Splitting on feature petal_length with gain ratio = 0.2918949098536057\n",
      "\n",
      "Level  3\n",
      "Count of Iris-versicolor = 37\n",
      "Current entropy is = 0.0\n",
      "Reached leaf node\n",
      "\n",
      "Level  3\n",
      "Count of Iris-virginica = 1\n",
      "Current entropy is = 0.0\n",
      "Reached leaf node\n",
      "\n",
      "Level  2\n",
      "Count of Iris-versicolor = 2\n",
      "Count of Iris-virginica = 39\n",
      "Current Entropy is = 0.2811937964320427\n",
      "Splitting on feature petal_length with gain ratio = 0.06981367359652843\n",
      "\n",
      "Level  3\n",
      "Count of Iris-versicolor = 2\n",
      "Count of Iris-virginica = 6\n",
      "Current Entropy is = 0.8112781244591328\n",
      "Splitting on feature sepal_width with gain ratio = 0.2567964389181899\n",
      "\n",
      "Level  4\n",
      "Count of Iris-virginica = 5\n",
      "Current entropy is = 0.0\n",
      "Reached leaf node\n",
      "\n",
      "Level  4\n",
      "Count of Iris-versicolor = 2\n",
      "Count of Iris-virginica = 1\n",
      "Current entropy is = 0.0\n",
      "Reached leaf node\n",
      "\n",
      "Level  3\n",
      "Count of Iris-virginica = 33\n",
      "Current entropy is = 0.0\n",
      "Reached leaf node\n"
     ]
    }
   ],
   "source": [
    "clf = myDecisionTreeClassifier(min_samples_split=3, max_depth=3,feature_list = f_list,target_list=t_list)\n",
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6e65b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = clf.predict(X_test) \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06069305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # graph pdf generate   ===> python-graphiz not working for my current custom model\n",
    "# from sklearn.tree import export_graphviz\n",
    "# import pydotplus\n",
    "\n",
    "# export_graphviz(clf,out_file='decision_tree.dot')\n",
    "# (tr,) = pydotplus.graph_from_dot_file('decision_tree.dot')\n",
    "# tr.write_pdf('demo.pdf')\n",
    "# # (graph,) = pydot.graph_from_dot_file('tree_from_forest.dot')\n",
    "# # graph.write_png('tree_from_forest.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cccad1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=10)\n",
    "model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee9e3023",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3871628ddde5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tree_iris.dot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tree_iris.dot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'demo.pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pydotplus/graphviz.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path, f, prog)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                 \u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1810\u001b[0;31m                 \u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m             )\n\u001b[1;32m   1812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pydotplus/graphviz.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, path, prog, format)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m                 \u001b[0mfobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pydotplus/graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format)\u001b[0m\n\u001b[1;32m   1957\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1958\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m                 raise InvocationException(\n\u001b[0m\u001b[1;32m   1960\u001b[0m                     'GraphViz\\'s executables not found')\n\u001b[1;32m   1961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "export_graphviz(model,out_file='tree_iris.dot')\n",
    "tr = pydotplus.graph_from_dot_file('tree_iris.dot')\n",
    "tr.write_pdf('demo.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f74e79fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement graphiz\u001b[0m\r\n",
      "\u001b[31mERROR: No matching distribution found for graphiz\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install graphiz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdea46a",
   "metadata": {},
   "source": [
    "# XOR Dataset \n",
    "    - full xor table is used as a dataset (4 rows , 3 cols[x1,x2,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b185d2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Level  0\n",
      "Count of 0 = 1\n",
      "Count of 1 = 3\n",
      "Current Entropy is = 0.8112781244591328\n",
      "Splitting on feature X1 with gain ratio = 0.15407786335091392\n",
      "\n",
      "Level  1\n",
      "Count of 0 = 1\n",
      "Count of 1 = 1\n",
      "Current Entropy is = 1.0\n",
      "Splitting on feature X2 with gain ratio = 0.5\n",
      "\n",
      "Level  2\n",
      "Count of 0 = 1\n",
      "Current entropy is = 0.0\n",
      "Reached leaf node\n",
      "\n",
      "Level  2\n",
      "Count of 1 = 1\n",
      "Current entropy is = 0.0\n",
      "Reached leaf node\n",
      "\n",
      "Level  1\n",
      "Count of 1 = 2\n",
      "Current entropy is = 0.0\n",
      "Reached leaf node\n"
     ]
    }
   ],
   "source": [
    "xor_dataset = pd.read_csv('xor.csv')\n",
    "X = xor_dataset.iloc[:, :-1].values\n",
    "Y = xor_dataset.iloc[:, -1].values.reshape(-1,1)\n",
    "clf_xor = myDecisionTreeClassifier(min_samples_split=2, max_depth=3,feature_list = ['X1','X2'],target_list=['0','1'])\n",
    "clf_xor.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01badb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # graph pdf generate\n",
    "# from sklearn.tree import export_graphviz\n",
    "# import pydotplus\n",
    "\n",
    "# export_graphviz(clf,out_file='decision_tree.dot')\n",
    "# (tr,) = pydotplus.graph_from_dot_file('decision_tree.dot')\n",
    "# tr.write_pdf('demo.pdf')\n",
    "# # (graph,) = pydot.graph_from_dot_file('tree_from_forest.dot')\n",
    "# # graph.write_png('tree_from_forest.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9b98b8",
   "metadata": {},
   "source": [
    " - unable to install graphiz module , so no pdf files available/uploading for tree visualization\n",
    "         - tried through conda - broken packages\n",
    "         - installed through pip3 but not compatabile with anaconda packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c18918e",
   "metadata": {},
   "source": [
    "## End Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a16131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
